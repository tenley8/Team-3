{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Toronto Covid-19 Cases**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data from PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# SQL \n",
    "from sqlalchemy import create_engine\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from config import db_password\n",
    "\n",
    "# ML Models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Connection Between PostgreSQL DB\n",
    "db_string = f\"postgres://postgres:{db_password}@module20covid.cgcfmenzscpu.us-east-2.rds.amazonaws.com:5432/postgres\"\n",
    "db = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL Query\n",
    "\n",
    "q = '''\n",
    "SELECT episode_date, tc.neighbourhood_name, age_group, gender, outcome, ever_hospitalized, ever_in_icu, ever_intubated, population_density, average_income, commute_public_transit, avg_temperature, avg_relative_humidity\n",
    "FROM \"Toronto_Cases\" tc\n",
    "INNER JOIN \"Toronto_Stats\" ts ON tc.neighbourhood_name = ts.neighbourhood_name\n",
    "LEFT JOIN (SELECT neighbourhood_name, (commute_car_driver::NUMERIC + commute_car_passenger::NUMERIC) / commute_total::NUMERIC AS \"commute_car\",\n",
    "commute_public_transit::NUMERIC / commute_total::NUMERIC AS \"commute_public_transit\", commute_walk::NUMERIC / commute_total::NUMERIC AS \"commute_walk\",\n",
    "commute_bicycle::NUMERIC / commute_total::NUMERIC AS \"commute_bicycle\", commute_other::NUMERIC / commute_total::NUMERIC AS \"commute_other\"\n",
    "FROM \"Toronto_Commute\"\n",
    ") commute ON tc.neighbourhood_name = commute.neighbourhood_name\n",
    "LEFT JOIN \"Toronto_Weather\" tw ON tc.episode_date = tw.date\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute SQL Query and Load Data into DataFrame\n",
    "toronto_df = pd.read_sql(sql=q, con=db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_date</th>\n",
       "      <th>neighbourhood_name</th>\n",
       "      <th>age_group</th>\n",
       "      <th>gender</th>\n",
       "      <th>outcome</th>\n",
       "      <th>ever_hospitalized</th>\n",
       "      <th>ever_in_icu</th>\n",
       "      <th>ever_intubated</th>\n",
       "      <th>population_density</th>\n",
       "      <th>average_income</th>\n",
       "      <th>commute_public_transit</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>avg_relative_humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-25</td>\n",
       "      <td>Malvern</td>\n",
       "      <td>50-59</td>\n",
       "      <td>MALE</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4948</td>\n",
       "      <td>29573</td>\n",
       "      <td>0.334200</td>\n",
       "      <td>5.65</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-20</td>\n",
       "      <td>Malvern</td>\n",
       "      <td>20-29</td>\n",
       "      <td>MALE</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4948</td>\n",
       "      <td>29573</td>\n",
       "      <td>0.334200</td>\n",
       "      <td>7.04</td>\n",
       "      <td>80.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>Malvern</td>\n",
       "      <td>60-69</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4948</td>\n",
       "      <td>29573</td>\n",
       "      <td>0.334200</td>\n",
       "      <td>3.35</td>\n",
       "      <td>71.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-02</td>\n",
       "      <td>Rouge</td>\n",
       "      <td>50-59</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1260</td>\n",
       "      <td>39556</td>\n",
       "      <td>0.276047</td>\n",
       "      <td>10.60</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>Rouge</td>\n",
       "      <td>30-39</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1260</td>\n",
       "      <td>39556</td>\n",
       "      <td>0.276047</td>\n",
       "      <td>11.45</td>\n",
       "      <td>58.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13069</th>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>West Humber-Clairville</td>\n",
       "      <td>50-59</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1117</td>\n",
       "      <td>31771</td>\n",
       "      <td>0.281220</td>\n",
       "      <td>13.20</td>\n",
       "      <td>79.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13070</th>\n",
       "      <td>2020-04-12</td>\n",
       "      <td>West Humber-Clairville</td>\n",
       "      <td>30-39</td>\n",
       "      <td>MALE</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1117</td>\n",
       "      <td>31771</td>\n",
       "      <td>0.281220</td>\n",
       "      <td>8.79</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13071</th>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>West Humber-Clairville</td>\n",
       "      <td>20-29</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1117</td>\n",
       "      <td>31771</td>\n",
       "      <td>0.281220</td>\n",
       "      <td>2.40</td>\n",
       "      <td>54.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13072</th>\n",
       "      <td>2020-05-23</td>\n",
       "      <td>West Humber-Clairville</td>\n",
       "      <td>20-29</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1117</td>\n",
       "      <td>31771</td>\n",
       "      <td>0.281220</td>\n",
       "      <td>18.79</td>\n",
       "      <td>68.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13073</th>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>West Humber-Clairville</td>\n",
       "      <td>50-59</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>RESOLVED</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1117</td>\n",
       "      <td>31771</td>\n",
       "      <td>0.281220</td>\n",
       "      <td>5.15</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13074 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      episode_date      neighbourhood_name age_group  gender   outcome  \\\n",
       "0       2020-03-25                 Malvern     50-59    MALE  RESOLVED   \n",
       "1       2020-03-20                 Malvern     20-29    MALE  RESOLVED   \n",
       "2       2020-03-04                 Malvern     60-69  FEMALE  RESOLVED   \n",
       "3       2020-05-02                   Rouge     50-59  FEMALE  RESOLVED   \n",
       "4       2020-05-31                   Rouge     30-39  FEMALE  RESOLVED   \n",
       "...            ...                     ...       ...     ...       ...   \n",
       "13069   2020-05-18  West Humber-Clairville     50-59  FEMALE  RESOLVED   \n",
       "13070   2020-04-12  West Humber-Clairville     30-39    MALE  RESOLVED   \n",
       "13071   2020-05-12  West Humber-Clairville     20-29  FEMALE  RESOLVED   \n",
       "13072   2020-05-23  West Humber-Clairville     20-29  FEMALE  RESOLVED   \n",
       "13073   2020-03-27  West Humber-Clairville     50-59  FEMALE  RESOLVED   \n",
       "\n",
       "       ever_hospitalized  ever_in_icu  ever_intubated  population_density  \\\n",
       "0                      0            0               0                4948   \n",
       "1                      1            0               0                4948   \n",
       "2                      1            1               1                4948   \n",
       "3                      0            0               0                1260   \n",
       "4                      0            0               0                1260   \n",
       "...                  ...          ...             ...                 ...   \n",
       "13069                  0            0               0                1117   \n",
       "13070                  0            0               0                1117   \n",
       "13071                  0            0               0                1117   \n",
       "13072                  0            0               0                1117   \n",
       "13073                  1            0               0                1117   \n",
       "\n",
       "       average_income  commute_public_transit  avg_temperature  \\\n",
       "0               29573                0.334200             5.65   \n",
       "1               29573                0.334200             7.04   \n",
       "2               29573                0.334200             3.35   \n",
       "3               39556                0.276047            10.60   \n",
       "4               39556                0.276047            11.45   \n",
       "...               ...                     ...              ...   \n",
       "13069           31771                0.281220            13.20   \n",
       "13070           31771                0.281220             8.79   \n",
       "13071           31771                0.281220             2.40   \n",
       "13072           31771                0.281220            18.79   \n",
       "13073           31771                0.281220             5.15   \n",
       "\n",
       "       avg_relative_humidity  \n",
       "0                       76.5  \n",
       "1                       80.5  \n",
       "2                       71.5  \n",
       "3                       63.0  \n",
       "4                       58.5  \n",
       "...                      ...  \n",
       "13069                   79.5  \n",
       "13070                   62.5  \n",
       "13071                   54.5  \n",
       "13072                   68.5  \n",
       "13073                   74.0  \n",
       "\n",
       "[13074 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview of DataFrame\n",
    "toronto_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "episode_date              datetime64[ns]\n",
       "neighbourhood_name                object\n",
       "age_group                         object\n",
       "gender                            object\n",
       "outcome                           object\n",
       "ever_hospitalized                  int64\n",
       "ever_in_icu                        int64\n",
       "ever_intubated                     int64\n",
       "population_density                 int64\n",
       "average_income                     int64\n",
       "commute_public_transit           float64\n",
       "avg_temperature                  float64\n",
       "avg_relative_humidity            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check Data Types\n",
    "toronto_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-3dd7069b3965>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-3dd7069b3965>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    print(f\"Column {column} has {toronto_df[column].isnull().sum()} null values\")a\u001b[0m\n\u001b[1;37m                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Inspecting for Null Values\n",
    "for column in toronto_df.columns:\n",
    "    print(f\"Column {column} has {toronto_df[column].isnull().sum()} null values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the Correlation between Aggregated Values\n",
    "toronto_df[['population_density', 'average_income', 'commute_public_transit']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Active Cases\n",
    "df = toronto_df[toronto_df['outcome'] != 'ACTIVE']\n",
    "# Replace UNKNOWN and TRANSGENDER by OTHER\n",
    "Other_Gender = ['UNKNOWN','TRANSGENDER','OTHER']\n",
    "for gender in Other_Gender:\n",
    "    df.gender = df.gender.replace(gender, \"OTHER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Binary Classification Model for Fatality\n",
    "#### 3.1 Pre-Processing (Encode, Split & Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame with Outcome & Dependent Variables Required for ML Models\n",
    "fatality_df = df[['outcome','age_group','gender','population_density','average_income','commute_public_transit']]\n",
    "fatality_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Categorical Variable List\n",
    "fatality_df_cat = fatality_df.dtypes[fatality_df.dtypes == \"object\"].index.tolist()\n",
    "fatality_df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OneHotEncoder Instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit the Encoder and Produce Encoded DataFrame\n",
    "encoded_df = pd.DataFrame(enc.fit_transform(fatality_df[fatality_df_cat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Encoded Columns\n",
    "encoded_df.columns = enc.get_feature_names(fatality_df_cat)\n",
    "encoded_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatality_df = fatality_df.merge(encoded_df, left_index=True, right_index=True)\n",
    "fatality_df = fatality_df.drop(fatality_df_cat,1)\n",
    "fatality_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = fatality_df['outcome_RESOLVED'].values\n",
    "X = fatality_df.drop(['outcome_FATAL','outcome_RESOLVED'],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Building ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net\n",
    "number_input_features = len(X_train[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 4\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=50) #epochs (run through the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=196, random_state=78)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance in the Random Forest model.\n",
    "importances = rf_model.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort the features by their importance.\n",
    "sorted(zip(rf_model.feature_importances_, fatality_df.drop(['outcome_FATAL','outcome_RESOLVED'],1).columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatality_feature_importance = rf_model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Binary Classification Model for Hospitalization\n",
    "#### 4.1 Pre-Processing (Encode, Split & Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame with Outcome & Dependent Variables Required for ML Models\n",
    "hospitalized_df = df[['ever_hospitalized','age_group','gender','population_density','average_income','commute_public_transit']]\n",
    "hospitalized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Categorical Variable List\n",
    "hospitalized_df_cat = hospitalized_df.dtypes[hospitalized_df.dtypes == \"object\"].index.tolist()\n",
    "hospitalized_df_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OneHotEncoder Instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit the Encoder and Produce Encoded DataFrame\n",
    "encoded_df = pd.DataFrame(enc.fit_transform(hospitalized_df[hospitalized_df_cat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename Encoded Columns\n",
    "encoded_df.columns = enc.get_feature_names(hospitalized_df_cat)\n",
    "encoded_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitalized_df = hospitalized_df.merge(encoded_df, left_index=True, right_index=True)\n",
    "hospitalized_df = hospitalized_df.drop(hospitalized_df_cat,1)\n",
    "hospitalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = hospitalized_df['ever_hospitalized'].values\n",
    "X = hospitalized_df.drop(['ever_hospitalized'],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Building ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=196, random_state=78)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "print(f\" Random forest predictive accuracy: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance in the Random Forest model.\n",
    "importances = rf_model.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort the features by their importance.\n",
    "sorted(zip(rf_model.feature_importances_, hospitalized_df.drop(['ever_hospitalized'],1).columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospitalized_feature_importance = rf_model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {'Variables': hospitalized_df.drop(['ever_hospitalized'],1).columns, \n",
    "          'Fatality': fatality_feature_importance, \n",
    "          'Hospitalized': hospitalized_feature_importance}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
